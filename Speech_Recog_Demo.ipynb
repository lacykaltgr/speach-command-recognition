{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTrNWNHLyaqF"
   },
   "source": [
    "\n",
    "# Speech Command Recognition\n",
    "\n",
    "This notebook presents an attention model for speech command recognotion. We use Google Speech Commands Dataset to test the Keras generator for sound files and the proposed RNN attention model.\n",
    "\n",
    "\n",
    "## Download files and load information\n",
    "\n",
    "Dynamically load speech data from the disk to allow handling big datasets.\n",
    "\n",
    "First step: download Google Speech Command Dataset and convert all WAV files to numpy arrays for faster load (about 10x faster than loading raw WAV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GieC2ZgNycMI"
   },
   "outputs": [],
   "source": [
    "useColab=False\n",
    "if useColab:\n",
    "    # Use tensorflow 2.10 or 2.11\n",
    "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/SpeechDownloader.py\n",
    "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/SpeechGenerator.py\n",
    "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/audioUtils.py\n",
    "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/SpeechModels.py\n",
    "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/requirements.txt\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "YTD7DrNlkhA0",
    "outputId": "7c07b106-5014-48a7-e370-a32220db0c9f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zJv_ttsyaqJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import SpeechDownloader\n",
    "import SpeechGenerator\n",
    "import SpeechModels\n",
    "import audioUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inp = tf.zeros( (2, 16000), dtype=tf.float32)\n",
    "inp.shape\n",
    "# audioUtils.normalized_mel_spectrogram( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inp * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stft = tf.signal.stft(\n",
    "    inp,\n",
    "    frame_length=1024,\n",
    "    frame_step=128,\n",
    "    window_fn=tf.signal.hann_window,\n",
    "    pad_end=True,\n",
    ")\n",
    "stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "a_sCoxN1yaqQ",
    "outputId": "4fb2ab07-d0c3-4d5c-f90a-ce95d2f7cafb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Download and prepare all data\n",
    "gscInfo, nCategs = SpeechDownloader.PrepareGoogleSpeechCmd(version=2, task='35word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzE5hypbyaqV"
   },
   "source": [
    "We should have 4 datasets, each with file names 'files' and their categories 'labels' in a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "U6g2xDpVyaqW",
    "outputId": "8786313b-175c-4f97-8ca2-9cd87ea28dce",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(gscInfo.keys())\n",
    "print(gscInfo['train'].keys())\n",
    "print(len(gscInfo['train']['files']))\n",
    "print(nCategs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kr5bibxhyaqa"
   },
   "source": [
    "# Speech Data Generator\n",
    "\n",
    "Use Keras to create a generator that reads files on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AXGWLGsGyaqc",
    "outputId": "ba82c9ba-6573-44f7-9cc6-6d0707add8ec",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sr = 16000 #we know this one for google audios\n",
    "iLen = 16000\n",
    "trainGen = SpeechGenerator.SpeechGen(gscInfo['train']['files'], gscInfo['train']['labels'], shuffle=True)\n",
    "# handle the fact that number of samples in validation may not be multiple of batch_size with shuffle=True\n",
    "valGen   = SpeechGenerator.SpeechGen(gscInfo['val']['files'], gscInfo['val']['labels'], shuffle=True)\n",
    "\n",
    "# use batch_size = total number of files to read all test files at once\n",
    "testGen  = SpeechGenerator.SpeechGen(gscInfo['test']['files'], gscInfo['test']['labels'], shuffle=False, batch_size=len(gscInfo['test']['files']))\n",
    "testRGen = SpeechGenerator.SpeechGen(gscInfo['testREAL']['files'], gscInfo['testREAL']['labels'], shuffle=False, batch_size=len(gscInfo['testREAL']['files']))\n",
    "valGen.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Q5bNHwXgyaqh",
    "outputId": "1ce74b95-8c5d-4cf4-fed9-311e7f8962be",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "audios, classes = valGen.__getitem__(5)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "0WUYY8akyaql",
    "outputId": "dcf63f52-9f4b-4cee-ea10-c54268660fb9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# librosa.output.write_wav('file.wav', audios[4], sr, norm=False)\n",
    "plt.plot(audios[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "1jz56x1Jyaqp",
    "outputId": "f9c4b538-4543-4266-f9b3-b6581b4311b7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "inp = L.Input((iLen,), name='input')\n",
    "mel_spec = audioUtils.normalized_mel_spectrogram(inp)\n",
    "melspecModel = Model(inputs=inp, outputs=mel_spec, name='normalized_spectrogram_model')\n",
    "\n",
    "melspecModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "audios.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EdDdxD-Cyaqt",
    "outputId": "62a0dec1-b39f-4758-c7e4-278be2c2e5cc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "melspec = melspecModel.predict(audios)\n",
    "melspec.shape\n",
    "\n",
    "np.min(melspec[9,:,:].T), np.max(melspec[9,:,:].T), np.mean(melspec[9,:,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "sg0mFYbEyaq0",
    "outputId": "4c509f32-986e-4284-e1f1-a25d1491294a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,9))\n",
    "plt.pcolormesh(melspec[9,:,:].T)\n",
    "\n",
    "plt.title('Spectrogram visualization')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enQjuF4Cmdch",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Check if mel spectrogram matches the one computed with librosa\n",
    "librosa_melspec = librosa.feature.melspectrogram(y=audios[9], sr=sr, n_fft=1024,\n",
    "                                                 hop_length=128, power=1.0, #window='hann',\n",
    "                                                 n_mels=80, fmin=40.0, fmax=sr/2)\n",
    "S_dB = librosa.power_to_db(librosa_melspec, ref=np.max)\n",
    "np.min(S_dB), np.max(S_dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "rtpQV8NIvGFZ",
    "outputId": "7451c43b-5987-4bc0-bfd3-49909a08d441",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,6))\n",
    "plt.pcolormesh(S_dB)\n",
    "\n",
    "plt.title('Spectrogram visualization - librosa')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcTD11oykhF4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# plt.hist(melspec.flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suRQj5Dayaq5"
   },
   "source": [
    "# Models\n",
    "\n",
    "Create Keras models to see if the generators are working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bArepYbcyaq7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "eJIjgckXyarF",
    "outputId": "b33e8bb3-289d-4abc-eb9b-fd5aa0b6ac35",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = SpeechModels.AttRNNSpeechModel(nCategs, samplingrate = sr, inputLength = None)#, rnn_func=L.LSTM)\n",
    "\n",
    "model.compile(optimizer='adam', loss=['sparse_categorical_crossentropy'], metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcqCM_YOkhGr",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# model.load_weights('model-attRNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uH8Aa4-gyarI",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.4\n",
    "    epochs_drop = 15.0\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "            math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    if (lrate < 4e-5):\n",
    "        lrate = 4e-5\n",
    "      \n",
    "    print('Changing learning rate to {}'.format(lrate))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "P4XKh-NdyarK",
    "outputId": "1e01985e-dd2c-4738-f296-b9c9a4da244f",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=10,\n",
    "                             verbose=1, restore_best_weights=True)\n",
    "checkpointer = ModelCheckpoint('model-attRNN.h5', monitor='val_sparse_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "results = model.fit(trainGen, validation_data=valGen, epochs=60, use_multiprocessing=False, workers=4, verbose=1,\n",
    "                    callbacks=[earlystopper, checkpointer, lrate])\n",
    "\n",
    "model.save('model-attRNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "KGaItJhiyarN",
    "outputId": "1d7e3b55-f39f-465d-9f4f-898bb002b917",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for categorical accuracy\n",
    "plt.plot(results.history['sparse_categorical_accuracy'])\n",
    "plt.plot(results.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('Categorical accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNUCmbUjkhIW",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Fgie8ZwyarQ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load best model according to cross-validation - model-attRNN\n",
    "# model = load_model('model-attRNN.h5', custom_objects={'Melspectrogram': Melspectrogram, 'Normalization2D': Normalization2D })\n",
    "model.load_weights('model-attRNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model, 'model-KWS-attRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlT2988zkhIg",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read all test data\n",
    "x_test, y_test = testGen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "O_R8ga27yarS",
    "outputId": "7d7a8a8f-c920-4013-e5ce-82b03b658606",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "valEval = model.evaluate(valGen, use_multiprocessing=False, workers=4,verbose=0)\n",
    "trainEval = model.evaluate(trainGen, use_multiprocessing=False, workers=4,verbose=0)\n",
    "testEval = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Evaluation scores: \\nMetrics: {} \\nTrain: {} \\nValidation: {} \\nTest: {}'.format(model.metrics_names, trainEval, valEval, testEval) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaM300dkyarV",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "kaggle12cmd = False\n",
    "if kaggle12cmd:\n",
    "    #only for the Kaggle competition, 12-cmd\n",
    "    x_testR, y_testR = testRGen.__getitem__(0)\n",
    "    testREval = model.evaluate(x_testR, y_testR, verbose=1)\n",
    "    print(testREval)\n",
    "    testREval = model.evaluate(testRGen, use_multiprocessing=True, workers=4,verbose=1)\n",
    "    print(testREval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbYaUxhfaH92"
   },
   "source": [
    "## Evaluation and Attention Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YaqNVpXjkhJA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "attSpeechModel = Model(inputs=model.input,\n",
    "                                 outputs=[model.get_layer('output').output, \n",
    "                                          model.get_layer('attSoftmax').output,\n",
    "                                          model.get_layer('tf.expand_dims').output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WEKcAAVkkhJE",
    "outputId": "5da7a1c9-6b0e-4834-ad25-6b1a5c4da24a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "audios, classes = valGen.__getitem__(3)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uUqczEllkhJX",
    "outputId": "c9870cd0-f165-4ff4-e255-01d8085fee9f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#8 - on, 13 - one, 7 - right\n",
    "idAudio = 8\n",
    "classes[idAudio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVdy6-8bkhJe",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "outs, attW, specs = attSpeechModel.predict(audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mPfWEgDMkhJi",
    "outputId": "1af17ee3-d8be-4768-9ebe-639d35ae896c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.argmax(outs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rE2kGpagkhJo",
    "outputId": "b29bfecd-f562-45c5-9b42-b05900a6ac8a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "specs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "colab_type": "code",
    "id": "8hyWMTslkhJu",
    "outputId": "b07da82b-9ffe-4e26-fa8a-79f69ac94dfd",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "imgHeight = 2\n",
    "\n",
    "plt.figure(figsize=(17,imgHeight))\n",
    "plt.title('Raw waveform', fontsize=30)\n",
    "plt.ylabel('Amplitude', fontsize=30)\n",
    "plt.xlabel('Sample index', fontsize=30)\n",
    "plt.plot(audios[idAudio])\n",
    "plt.savefig('picrawWave.png', dpi = 400)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(17,imgHeight))\n",
    "plt.title('Attention weights (log)', fontsize=30)\n",
    "plt.ylabel('Log of attention weight', fontsize=30)\n",
    "plt.xlabel('Mel-spectrogram index', fontsize=30)\n",
    "plt.plot(np.log(attW[idAudio]))\n",
    "plt.savefig('picAttention.png', dpi = 400)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,imgHeight*2))\n",
    "plt.pcolormesh(specs[idAudio,:,:,0].T)\n",
    "\n",
    "plt.title('Spectrogram visualization', fontsize=30)\n",
    "plt.ylabel('Frequency', fontsize=30)\n",
    "plt.xlabel('Time', fontsize=30)\n",
    "plt.savefig('picmelSpec.png', dpi = 400)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Nvdo2FiJkhJz",
    "outputId": "32e2cadb-051a-48d3-a65c-a0cb2ee9c952",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jAPOwlxUkhJ5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import audioUtils\n",
    "cm = confusion_matrix(y_test, np.argmax(y_pred,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CJnhiCbkhJ6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#set(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qzp7RWnQkhKA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#35word, v2\n",
    "classes = ['nine', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go',\n",
    "           'zero', 'one', 'two', 'three', 'four', 'five', 'six', \n",
    "           'seven',  'eight', 'backward', 'bed', 'bird', 'cat', 'dog',\n",
    "           'follow', 'forward', 'happy', 'house', 'learn', 'marvin', 'sheila', 'tree',\n",
    "           'visual', 'wow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3Pq8U-EkhKS",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#35word, v1\n",
    "#classes=['nine', 'yes',  'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go',\n",
    "#         'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven',  'eight', \n",
    "#         'bed', 'bird', 'cat', 'dog', 'happy', 'house', \n",
    "#         'marvin', 'sheila', 'tree', 'wow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJkO4oBGkhKr",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#20cmd\n",
    "#classes=['unknown', 'nine', 'yes',  'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go',\n",
    "#         'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven',  'eight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wL1IIdLrkhK2",
    "outputId": "acd0a55a-dc1e-4d1b-f7b0-1f0b0aeb67d2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "audioUtils.plot_confusion_matrix(cm, classes, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JeZEuX3kkhK6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eryXTX2JkhLD",
    "outputId": "75710504-c133-4231-ca75-5cd52b4541c0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "[tf.__version__, pd.__version__, librosa.__version__]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGsYylzrq9P5"
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_16000 = SpeechModels.AttRNNSpeechModel(nCategs, samplingrate = sr, inputLength = None)\n",
    "model_16000.load_weights('model-attRNN.h5')\n",
    "\n",
    "tf.saved_model.save(model_16000, 'model-KWS-attRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_16000 = tf.saved_model.load('model-KWS-attRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28YtNROt8hjF",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('model-KWS-attRNN') # path to the SavedModel directory\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model-KWS-attRNN.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Speech_Recog_Demo.ipynb",
   "provenance": []
  },
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
